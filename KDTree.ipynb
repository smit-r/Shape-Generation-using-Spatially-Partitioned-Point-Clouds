{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KDTree.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smit-r/Shape-Generation-using-Spatially-Partitioned-Point-Clouds/blob/main/KDTree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xujXfqvMaR7i"
      },
      "source": [
        "!python -m pip install open3d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr6NOZFVDMM7"
      },
      "source": [
        "import numpy as np\n",
        "import scipy as scy\n",
        "import os\n",
        "import open3d\n",
        "import numpy as np\n",
        "import sklearn.decomposition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXfUcQlsaEwC"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvMiK8q-aFrK",
        "outputId": "f9fd7a2a-e663-438b-aeb0-0863b68db38b"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/shapenet_chair_data/shapenet-chairs-pcd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/shapenet_chair_data/shapenet-chairs-pcd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yu-z1DPaVr_"
      },
      "source": [
        "#### KDTree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMtK_pKRDv_B"
      },
      "source": [
        "## performs kdtree sorting on pointcloud\n",
        "def kdtree(pointCloud, level):\n",
        "  if (len(pointCloud)<=1):\n",
        "    return pointCloud\n",
        "  pointlist = np.array(pointCloud)\n",
        "  plane = getPlane(level)\n",
        "  median = getkthPosition(pointlist, plane, 0, len(pointlist)-1, int(len(pointlist)/2))\n",
        "  leftArray = median[:int(len(median)/2)]\n",
        "  rightArray = median[int((len(median)/2))+1:]\n",
        "  leftSortedArray = kdtree(leftArray, level+1)\n",
        "  rightSortedArray = kdtree(rightArray, level+1)\n",
        "  return np.concatenate((leftSortedArray, [median[int(len(median)/2)]], rightSortedArray))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njkozMnBEL3a"
      },
      "source": [
        "def getPlane(level):\n",
        "  plane = level%3\n",
        "  return plane"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnKgdpluHLEm"
      },
      "source": [
        "def getPartition(pointlist, axis, l, r):\n",
        "  i = l\n",
        "  x = pointlist[r, axis]\n",
        "  for j in range(l, r):\n",
        "    if pointlist[j,axis]<x:\n",
        "      pointlist[[i,j]] = pointlist[[j,i]]\n",
        "      i += 1\n",
        "  pointlist[[i,r]] = pointlist[[r,i]]\n",
        "  return i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txBstj68WoLr"
      },
      "source": [
        "def getkthPosition(pointlist, axis, l, r, k):\n",
        "  i = getPartition(pointlist, axis, l, r)\n",
        "  if (l>r):\n",
        "    return np.array([])\n",
        "  if (i == k):\n",
        "    return pointlist\n",
        "  elif (i == r):\n",
        "    return getkthPosition(pointlist, axis, l, r-1, k)\n",
        "  elif (i < k):\n",
        "    return getkthPosition(pointlist, axis, i+1, r, k)\n",
        "  else:\n",
        "    return getkthPosition(pointlist, axis, l, i-1, k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKFhWBGwVPRM"
      },
      "source": [
        "#### PCA Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6-U06A8WUTh"
      },
      "source": [
        "## load the dataset\n",
        "dataset = []\n",
        "for f in os.listdir():\n",
        "  if f[-4:]==\".pcd\":\n",
        "    pcd = open3d.io.read_point_cloud(f)\n",
        "    pointcloud = np.asarray(pcd.points)\n",
        "    dataset.append(pointcloud)\n",
        "  print(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqEG_AiMWzeg"
      },
      "source": [
        "# sort using KDTree\n",
        "data = np.array(dataset)\n",
        "for i in range(len(dataset)):\n",
        "  shape = data[i]\n",
        "  shape = kdtree(shape, 0)\n",
        "  data[i] = shape\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifBiICfqXsh2",
        "outputId": "5d4b8db3-3bef-47be-a163-c6b7dae62d3c"
      },
      "source": [
        "# construct matrix P\n",
        "P = np.reshape(data, [5000,-1]) #(5000, 3000)\n",
        "mean = np.mean(P, axis=0) #(5000, )\n",
        "Pu = P - mean #P[i]-mean\n",
        "Pu.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 3000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyx828f1YlG0"
      },
      "source": [
        "# PCA\n",
        "def pcaAnalysis(Pu):\n",
        "  pca = sklearn.decomposition.PCA(n_components=100)\n",
        "  pca.fit(Pu)\n",
        "  comp = pca.components_\n",
        "  return comp\n",
        "\n",
        "comp = pcaAnalysis(Pu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQvIQ_VHZagd",
        "outputId": "065b96ac-5311-4327-f78c-2ff19640466a"
      },
      "source": [
        "# transform and reconstruct\n",
        "Pcomp = np.dot(Pu, comp.T)\n",
        "print(Pcomp.shape)\n",
        "Precon = np.dot(Pcomp, comp)\n",
        "print(Precon.shape)\n",
        "errors = Pu - Precon\n",
        "errors = errors*errors #calculate errors for each shape\n",
        "print(errors.shape)\n",
        "errors = np.sum(errors, axis=1) #(5000, )\n",
        "print(errors.shape)\n",
        "errlist = [errors]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 100)\n",
            "(5000, 3000)\n",
            "(5000, 3000)\n",
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqINs-3_ag9Y"
      },
      "source": [
        "# sample two points randomly\n",
        "def samplePoints():\n",
        "  points = np.random.randint(0,1000, 2)\n",
        "  return points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JSLr--ScIVD"
      },
      "source": [
        "# swap points\n",
        "def swap(shape, points):\n",
        "  shape[3*points[0]], shape[3*points[1]] = shape[3*points[1]], shape[3*points[0]] # swap x\n",
        "  shape[3*points[0]+1], shape[3*points[1]+1] = shape[3*points[1]+1], shape[3*points[0]+1] #swap y\n",
        "  shape[3*points[0]+2], shape[3*points[1]+2] = shape[3*points[1]+2], shape[3*points[0]+2] #swap z\n",
        "  return shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAaLBHqtg5mr"
      },
      "source": [
        "# calculate error\n",
        "def error(shape, shape_):\n",
        "  err = shape - shape_\n",
        "  err = np.dot(err.T, err)\n",
        "  return err"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL2OqDqTduar"
      },
      "source": [
        "# ordering using PCA Reconstruction Error\n",
        "# as given in paper\n",
        "save_path = '/content/drive/My Drive/'\n",
        "k = 10**4\n",
        "count = 0\n",
        "errs = errlist[0][0]\n",
        "for s in range(len(Pu)):\n",
        "  for i in range(k):\n",
        "    shape = np.array(Pu[s])\n",
        "    points = samplePoints() # sample two points\n",
        "    shape = swap(shape, points)\n",
        "    shapecomp = np.dot(shape.T, comp.T) # transform\n",
        "    shaperecon = np.dot(shapecomp.T, comp) # inverse_transform\n",
        "    err = error(shape, shaperecon)\n",
        "    if err<errs:\n",
        "      Pu[s] = shape\n",
        "      count += 1\n",
        "    else:\n",
        "      continue\n",
        "  print(count, s)\n",
        "  comp = pcaAnalysis(Pu) # calculate new components\n",
        "  #calculate error for next shape\n",
        "  if s<len(Pu-1):\n",
        "    shape = Pu[s+1]\n",
        "    shapecomp = np.dot(shape.T, comp.T)\n",
        "    shaperecon = np.dot(shapecomp.T, comp)\n",
        "    errs = error(shape, shaperecon)\n",
        "  if s%50==0 or s==len(Pu)-1: #calculate errors for each shape and store in errlist\n",
        "    Pcomp = np.dot(Pu, comp.T)\n",
        "    Precon = np.dot(Pcomp, comp)\n",
        "    errors = Pu - Precon\n",
        "    errors = errors*errors\n",
        "    errors = np.sum(errors, axis=1)\n",
        "    errlist.append(errors)\n",
        "    np.save(save_path+'errlist', np.array(errlist))\n",
        "    np.save(save_path+'Pu', Pu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yoaqtdhkMDP"
      },
      "source": [
        "## results after performing swaping for 1000 shapes\n",
        "\n",
        "[Reconstruction Error](https://drive.google.com/file/d/1MGAZNpFGKdh0b-mEuOIDiWvut3WGs_vA/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RR-KR22l62M"
      },
      "source": [
        "def swapAll(Pu, Points):\n",
        "  for i in range(len(points)):\n",
        "    Pu[i] = swap(Pu[i], points[i])\n",
        "  return Pu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78CFlxNQJxg9"
      },
      "source": [
        "def sampleAll():\n",
        "  points = np.random.randint(0,1000,(5000,2))\n",
        "  return points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6vKHDuCvmMy"
      },
      "source": [
        "def errAll(Pu_, comp):\n",
        "  Pcomp = np.dot(Pu_, comp.T)\n",
        "  Precon = np.dot(Pcomp, comp)\n",
        "  errors = Pu_ - Precon\n",
        "  errors = errors*errors\n",
        "  errors = np.sum(errors, axis=1)\n",
        "  return errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a-1XxjPv-ve",
        "outputId": "ac9b7bb6-8531-4c12-f74e-12ebd7fed1bd"
      },
      "source": [
        "#### optimized trainig loop\n",
        "save_path = '/content/drive/My Drive/'\n",
        "for iter in range(1000):\n",
        "  for k in range(10*4):\n",
        "    Pu_ = np.array(Pu)\n",
        "    points = sampleAll()\n",
        "    Pu_ = swapAll(Pu_, points)\n",
        "    # calculate error\n",
        "    err = errAll(Pu_, comp)\n",
        "    # compare\n",
        "    bin = (err<errors).astype(int)\n",
        "    binPu = np.array([bin]*3000).T\n",
        "    Pu = ((1-binPu)*Pu) + (binPu*Pu_) # select shapes to be swaped and swap them\n",
        "  comp = pcaAnalysis(Pu)\n",
        "  errors = errAll(Pu, comp)\n",
        "  errlist.append(errors)\n",
        "  np.save(save_path+'vec_errlist', np.array(errlist))\n",
        "  np.save(save_path+'vec_Pu', Pu)\n",
        "  print(iter, np.sum(errors))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 19569.186676428057\n",
            "1 19551.682837160115\n",
            "2 19534.242262590767\n",
            "3 19517.54166685394\n",
            "4 19499.15250251531\n",
            "5 19481.24865742768\n",
            "6 19461.755500221647\n",
            "7 19443.155743331066\n",
            "8 19426.312453648843\n",
            "9 19408.023807837657\n",
            "10 19391.9302040219\n",
            "11 19374.626828593668\n",
            "12 19359.42740421809\n",
            "13 19340.48563459366\n",
            "14 19323.222387808884\n",
            "15 19307.179904682227\n",
            "16 19289.406884801683\n",
            "17 19274.298867871476\n",
            "18 19256.775584632076\n",
            "19 19241.893916388755\n",
            "20 19224.51585749694\n",
            "21 19208.877942698113\n",
            "22 19192.2439250288\n",
            "23 19175.792603144146\n",
            "24 19159.745262332555\n",
            "25 19144.023659963445\n",
            "26 19128.219691463135\n",
            "27 19112.40878709018\n",
            "28 19095.92056188584\n",
            "29 19081.42357771124\n",
            "30 19064.46574667252\n",
            "31 19049.030930089324\n",
            "32 19033.560697122375\n",
            "33 19018.273393434436\n",
            "34 19003.419103827797\n",
            "35 18988.29438052002\n",
            "36 18972.776709414433\n",
            "37 18957.19772639135\n",
            "38 18941.916563718325\n",
            "39 18926.90538135384\n",
            "40 18912.358405146922\n",
            "41 18896.91853771838\n",
            "42 18881.97412656741\n",
            "43 18866.7176170365\n",
            "44 18851.540123979612\n",
            "45 18836.89720453243\n",
            "46 18822.94732695696\n",
            "47 18808.313728837817\n",
            "48 18793.522088642425\n",
            "49 18779.295664201913\n",
            "50 18765.222417085814\n",
            "51 18750.89472949181\n",
            "52 18736.54655263888\n",
            "53 18721.65801110284\n",
            "54 18707.52923732958\n",
            "55 18693.34578886174\n",
            "56 18679.406898760142\n",
            "57 18665.63536277277\n",
            "58 18651.200623939556\n",
            "59 18637.748165102763\n",
            "60 18623.370862947962\n",
            "61 18609.363399350514\n",
            "62 18595.490826181027\n",
            "63 18581.351322979295\n",
            "64 18567.74372537672\n",
            "65 18553.771176222508\n",
            "66 18540.061389093255\n",
            "67 18526.277711221173\n",
            "68 18512.67275842012\n",
            "69 18498.978681235567\n",
            "70 18486.09997353367\n",
            "71 18472.80441922627\n",
            "72 18459.67592624453\n",
            "73 18445.786592080287\n",
            "74 18432.320734477034\n",
            "75 18419.575187697785\n",
            "76 18406.220036166786\n",
            "77 18393.074553910148\n",
            "78 18379.878879304728\n",
            "79 18366.732438392482\n",
            "80 18353.671799065512\n",
            "81 18340.665671029266\n",
            "82 18327.520376600478\n",
            "83 18314.63648967143\n",
            "84 18301.85024925178\n",
            "85 18288.916355089696\n",
            "86 18275.887243336452\n",
            "87 18262.88819669558\n",
            "88 18249.72212616783\n",
            "89 18236.50795768734\n",
            "90 18224.156337721484\n",
            "91 18211.69368367471\n",
            "92 18198.57206945929\n",
            "93 18185.939530309624\n",
            "94 18173.140057064484\n",
            "95 18160.341426988973\n",
            "96 18147.112598800137\n",
            "97 18134.124398653374\n",
            "98 18121.370528082814\n",
            "99 18109.086665248797\n",
            "100 18096.666590385834\n",
            "101 18084.471630529915\n",
            "102 18071.616429547863\n",
            "103 18059.426346496086\n",
            "104 18047.34053515592\n",
            "105 18034.8062691975\n",
            "106 18022.4504479196\n",
            "107 18009.662873021593\n",
            "108 17997.156266588252\n",
            "109 17984.755237807716\n",
            "110 17972.837975755596\n",
            "111 17960.555779256792\n",
            "112 17948.099170870377\n",
            "113 17935.6252146562\n",
            "114 17923.11138908282\n",
            "115 17911.154671156666\n",
            "116 17899.109622741045\n",
            "117 17887.034887416008\n",
            "118 17875.3881936673\n",
            "119 17863.60470280247\n",
            "120 17851.795479944773\n",
            "121 17839.77821327539\n",
            "122 17827.96007086222\n",
            "123 17816.173726229492\n",
            "124 17804.744970577856\n",
            "125 17793.036548450596\n",
            "126 17780.97885697591\n",
            "127 17769.14051568893\n",
            "128 17757.135679407267\n",
            "129 17745.304019650634\n",
            "130 17733.68736450193\n",
            "131 17722.385730196158\n",
            "132 17710.3365334013\n",
            "133 17698.491008123525\n",
            "134 17686.58994237989\n",
            "135 17674.92821142475\n",
            "136 17663.759896885997\n",
            "137 17652.591659967853\n",
            "138 17640.53343761029\n",
            "139 17629.258273605366\n",
            "140 17617.762537161718\n",
            "141 17606.464832688805\n",
            "142 17595.372086376265\n",
            "143 17584.08978059606\n",
            "144 17573.093304147347\n",
            "145 17561.801400615783\n",
            "146 17550.56291053912\n",
            "147 17539.39411167541\n",
            "148 17528.089683937367\n",
            "149 17516.901650117612\n",
            "150 17505.898655033514\n",
            "151 17494.478800093188\n",
            "152 17483.316430920582\n",
            "153 17472.358177854152\n",
            "154 17461.602656161856\n",
            "155 17450.25186515972\n",
            "156 17438.978554873993\n",
            "157 17427.579419096262\n",
            "158 17416.3662519653\n",
            "159 17405.409251889087\n",
            "160 17394.528407217265\n",
            "161 17383.346128390906\n",
            "162 17372.428575021964\n",
            "163 17361.731349363014\n",
            "164 17350.88637196923\n",
            "165 17340.180462514756\n",
            "166 17329.592291781148\n",
            "167 17318.724223163663\n",
            "168 17308.123084939012\n",
            "169 17297.115590208195\n",
            "170 17286.165500391908\n",
            "171 17275.65824866659\n",
            "172 17264.94931577623\n",
            "173 17254.659199159247\n",
            "174 17244.12881928602\n",
            "175 17233.531227943993\n",
            "176 17222.99794362911\n",
            "177 17212.17347873283\n",
            "178 17202.059979941718\n",
            "179 17191.72474737665\n",
            "180 17180.900229171424\n",
            "181 17170.57464445103\n",
            "182 17160.063069191157\n",
            "183 17149.886771614474\n",
            "184 17139.353942173533\n",
            "185 17128.99501538476\n",
            "186 17118.464114909166\n",
            "187 17108.066964678364\n",
            "188 17098.14049981186\n",
            "189 17087.659461827818\n",
            "190 17077.334643746904\n",
            "191 17067.110554167684\n",
            "192 17056.472571618557\n",
            "193 17046.359923632775\n",
            "194 17035.94521568141\n",
            "195 17025.624073834748\n",
            "196 17015.291006107822\n",
            "197 17005.037078751804\n",
            "198 16994.85253945811\n",
            "199 16984.39085117582\n",
            "200 16974.06110905035\n",
            "201 16963.875271483375\n",
            "202 16953.628437990526\n",
            "203 16943.548815275855\n",
            "204 16933.724024805335\n",
            "205 16923.995181660153\n",
            "206 16913.81628195085\n",
            "207 16903.63751286809\n",
            "208 16893.936321983274\n",
            "209 16883.76341244813\n",
            "210 16873.684652011645\n",
            "211 16863.748571157026\n",
            "212 16853.584943823436\n",
            "213 16843.59875711621\n",
            "214 16833.718951679424\n",
            "215 16823.738597606505\n",
            "216 16813.99682180579\n",
            "217 16804.122067918885\n",
            "218 16794.387064939172\n",
            "219 16784.150366114747\n",
            "220 16774.17154882279\n",
            "221 16764.186043302354\n",
            "222 16754.229475903685\n",
            "223 16744.598405245524\n",
            "224 16734.809949830807\n",
            "225 16725.115468840733\n",
            "226 16715.415049408177\n",
            "227 16705.766899362035\n",
            "228 16696.27114027638\n",
            "229 16686.463037930855\n",
            "230 16676.62577589124\n",
            "231 16667.13097817726\n",
            "232 16657.465993757483\n",
            "233 16647.79864485896\n",
            "234 16638.42477609834\n",
            "235 16628.608863818787\n",
            "236 16619.14018289568\n",
            "237 16609.500958885506\n",
            "238 16600.302693270238\n",
            "239 16590.9792447199\n",
            "240 16581.37273877699\n",
            "241 16572.069927611083\n",
            "242 16562.57861858116\n",
            "243 16553.065426752062\n",
            "244 16543.96547376732\n",
            "245 16534.615005832544\n",
            "246 16524.998192781655\n",
            "247 16515.404756347893\n",
            "248 16506.09763228839\n",
            "249 16496.566574503246\n",
            "250 16487.11219590745\n",
            "251 16477.77139126722\n",
            "252 16467.962549752825\n",
            "253 16458.359908955503\n",
            "254 16449.221433240244\n",
            "255 16439.99561425478\n",
            "256 16430.619145700184\n",
            "257 16421.19164335652\n",
            "258 16412.057453656034\n",
            "259 16402.82181299434\n",
            "260 16393.722601869595\n",
            "261 16384.345471509037\n",
            "262 16374.826920672778\n",
            "263 16365.777841315568\n",
            "264 16356.68007564891\n",
            "265 16347.298266161408\n",
            "266 16337.622964836246\n",
            "267 16328.692636889658\n",
            "268 16319.275903761616\n",
            "269 16309.98439565414\n",
            "270 16300.77694634825\n",
            "271 16291.943748841784\n",
            "272 16283.131297289165\n",
            "273 16274.108686126507\n",
            "274 16265.406680630289\n",
            "275 16256.596026599478\n",
            "276 16247.895530746971\n",
            "277 16238.977237396877\n",
            "278 16230.111987821558\n",
            "279 16221.171227514225\n",
            "280 16211.856826436706\n",
            "281 16202.852874742277\n",
            "282 16194.169535075129\n",
            "283 16185.338107589583\n",
            "284 16176.386359071486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJgUr5HPlNK_"
      },
      "source": [
        "## results after 400 iterations\n",
        "\n",
        "[Reconstruction Error](https://drive.google.com/file/d/1-46E_roxPaFlTNoULcBjBYmD3uCfdoRH/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbSOOr9Jez1T"
      },
      "source": [
        "#### GAN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrT4INXGewqH"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-7vQf6CQdAn"
      },
      "source": [
        "class Generator(layers.Layer):\n",
        "\n",
        "    def __init__(self, dim=100, name=\"Generator\", **kwargs):\n",
        "        super(Generator, self).__init__(name=name, **kwargs)\n",
        "        self.layer1 = layers.Dense(dim, activation='relu')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.layer2 = layers.Dense(dim, activation='relu')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        self.layer3 = layers.Dense(dim, activation='relu')\n",
        "        self.bn3 = layers.BatchNormalization()\n",
        "        self.layer4 = layers.Dense(dim, activation='relu')\n",
        "        self.bn4 = layers.BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.layer1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x2 = self.layer2(x)\n",
        "        x2 = self.bn2(x2)\n",
        "        x3 = self.layer3(x2)\n",
        "        x3 = self.bn3(x3)\n",
        "        x4 = self.layer4(x3)\n",
        "        x4 = self.bn4(x4)\n",
        "        return x4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYrx5QMgQiAv"
      },
      "source": [
        "class Discriminator(layers.Layer):\n",
        "\n",
        "    def __init__(self, dim=100, name=\"Discriminator\", **kwargs):\n",
        "        super(Discriminator, self).__init__(name=name, **kwargs)\n",
        "        self.layer1 = layers.Dense(dim, activation='relu')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.layer2 = layers.Dense(dim, activation='relu')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        self.layer3 = layers.Dense(dim, activation='relu')\n",
        "        self.bn3 = layers.BatchNormalization()\n",
        "        self.layer4 = layers.Dense(dim, activation='relu')\n",
        "        self.bn4 = layers.BatchNormalization()\n",
        "        self.outlayer = layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x1 = self.layer1(inputs)\n",
        "        x1 = self.bn1(x1)\n",
        "        x2 = self.layer2(x1)\n",
        "        x2 = self.bn2(x2)\n",
        "        x3 = self.layer3(x2)\n",
        "        x3 = self.bn3(x3)\n",
        "        x4 = self.layer4(x3)\n",
        "        x4 = self.bn4(x4)\n",
        "        pred = self.outlayer(x4)\n",
        "        return x1,x2,x3,x4,pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvRdyG29Qk2D"
      },
      "source": [
        "def gen_loss_fn(fake, real):\n",
        "  # expectation term\n",
        "  lossE = 0\n",
        "  lossCov = 0\n",
        "  for i in range(len(real)):\n",
        "    lossE += tf.math.reduce_sum(tf.math.square(tf.math.reduce_mean(real[i], axis=0) - tf.math.reduce_mean(fake[i], axis=0)))\n",
        "    covfx = tf.linalg.matmul((real[i] - tf.math.reduce_mean(real[i], axis=0)), (real[i] - tf.math.reduce_mean(real[i], axis=0)), transpose_a=True, transpose_b=False)\n",
        "    covfgx = tf.linalg.matmul((fake[i] - tf.math.reduce_mean(fake[i], axis=0)), (fake[i] - tf.math.reduce_mean(fake[i], axis=0)), transpose_a=True, transpose_b=False)\n",
        "    lossCov += tf.math.square(tf.norm(covfx - covfgx))\n",
        "  return lossE + lossCov"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_OS1n-tQor8"
      },
      "source": [
        "## training loop\n",
        "gen = Generator(dim=100)\n",
        "dis = Discriminator(dim=100)\n",
        "\n",
        "gen_opt = keras.optimizers.Adam()\n",
        "dis_opt = keras.optimizers.Adam()\n",
        "\n",
        "d_loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "@tf.function\n",
        "def train_step(shape_coeff):\n",
        "  ## sample noise vectors\n",
        "  noise = tf.random.uniform(shape=shape_coeff.shape, minval=-1, maxval=1) ## (batch_size, 100)\n",
        "  ## get generator output\n",
        "  gen_shape_coeff = gen(noise) ## (batch_size, 100)\n",
        "  comb_shape_coeff = tf.concat([gen_shape_coeff, shape_coeff], axis=0) ## (2*batch_size, 100)\n",
        "  ## generate labels\n",
        "  labels = tf.concat([tf.ones(gen_shape_coeff.shape[0],1), tf.zeros(shape_coeff.shape[0],1)], axis=0) ## (2*batch_size, 1)\n",
        "  labels += 0.05*tf.random.uniform(labels.shape) \n",
        "\n",
        "  ## train the discriminator\n",
        "  with tf.GradientTape() as tape:\n",
        "    pred = dis(comb_shape_coeff)[-1] ## (2*batch_size, 1)\n",
        "    d_loss = d_loss_fn(labels, pred)\n",
        "  grads = tape.gradient(d_loss, dis.trainable_weights)\n",
        "  dis_opt.apply_gradients(zip(grads, dis.trainable_weights))\n",
        "\n",
        "  #sample noise for gen training\n",
        "  noise_g = tf.random.uniform(shape=shape_coeff.shape, minval=-1, maxval=1) ## (batch_size, 100)\n",
        "  #get discriminator output for real data\n",
        "  dis_output = dis(shape_coeff) ## (x1,x2,x3,x4,pred)\n",
        "\n",
        "  ## train the generator\n",
        "  with tf.GradientTape() as tape:\n",
        "    pred_g = dis(gen(noise_g)) ## (x1,x2,x3,x4,pred)\n",
        "    g_loss = gen_loss_fn(dis_output, pred_g)\n",
        "  grads = tape.gradient(g_loss, gen.trainable_weights)\n",
        "  gen_opt.apply_gradients(zip(grads, gen.trainable_weights))\n",
        "  return d_loss, g_loss, gen_shape_coeff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd2OB9aQbB2y"
      },
      "source": [
        "Pcomp = np.dot(Pu, comp.T )\n",
        "Pcomp = Pcomp.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7xVEYZnQsYc",
        "outputId": "eb825bdb-edd6-4674-bf12-132e3927161d"
      },
      "source": [
        "## set betch_Size and epochs here and run this cell for training\n",
        "\n",
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(Pcomp)\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "\n",
        "epochs = 1\n",
        "save_dir = ''\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(\"\\nstart epoch\", epoch)\n",
        "  for step, batch in enumerate(dataset):\n",
        "    # train step\n",
        "    d_loss, g_loss, gen_shape_coeff = train_step(batch)\n",
        "\n",
        "    #logging\n",
        "    if step%50==0:\n",
        "      print(\"discriminator loss at step %d: %.2f\" % (step, d_loss))\n",
        "      print(\"generator loss at step %d: %.2f\" % (step, g_loss))\n",
        "\n",
        "\n",
        "      # save weights and gen_outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "start epoch 0\n",
            "discriminator loss at step 0: 0.72\n",
            "generator loss at step 0: 7713.96\n",
            "discriminator loss at step 50: 0.49\n",
            "generator loss at step 50: 297497.19\n",
            "discriminator loss at step 100: 0.49\n",
            "generator loss at step 100: 396538.44\n",
            "discriminator loss at step 150: 0.49\n",
            "generator loss at step 150: 450521.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTjUmo-zqTXN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}